---
title: "Ambiguità di fondo"
date: "2023-03-24"
description: "Antropomorfismo, ovvero l'ambiguità di fondo su cui poggia l'intelligenza artificiale."
summary: "Antropomorfismo, ovvero l'ambiguità di fondo su cui poggia l'intelligenza artificiale."
tags: 
  - "intelligenza artificiale"
  - "gpt"
  - "antropomorfismo"
  - "ia generativa"
---

Siamo tutti immersi, io per primo, nell'hype collettivo delle intelligenze artificiali generative. Mentre conversiamo con loro dei massimi sistemi o creiamo immagini sempre più sorprendenti è bene affiancare all'entusiasmo qualche pensiero che viaggia in direzione opposta.

In particolare, per quanto riguarda i modelli linguistici alla base di tecnologie come ChatGPT, sono usciti nelle ultime settimane diversi articoli che ne evidenziano la natura complessa e sfaccettata: se da un lato sono innegabilmente impressionanti per la loro capacità di generare risposte coerenti e adeguate al contesto (pur senza averne comprensione), dall'altro sollevano importanti questioni sulla natura del linguaggio, sui limiti dei modelli statistici e sulle potenziali implicazioni etiche di queste tecnologie.

Ne segnalo in particolare tre:

1. [ChatGPT Is a Blurry JPEG of the Web](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) di Ted Chiang
2. [You Are Not a Parrot](https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html) di Elizabeth Weil
3. [The False Promise of ChatGPT](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html) di Noam Chomsky, Ian Roberts e Jeffrey Watumull

Le critiche che emergono, come l'incapacità di comprendere il significato e il contesto, la mancanza di senso morale, i bias e le allucinazioni, poggiano tutte su un'ambiguità di fondo: la tendenza ad attribuire a questi sistemi caratteristiche, emozioni e comportamenti umani (antropomorfismo).
Questa propensione sembra essere, da un lato, un riflesso dei nostri istinti sociali innati: gli esseri umani sono creature sociali che si sono evolute per interagire tra loro in modi complessi e sono di conseguenza portati a trattare qualsiasi entità che mostri un comportamento simile come un membro dello stesso gruppo sociale.
D'altro canto però, c'è una precisa scelta di design da parte delle aziende produttrici. Le IA vengono progettate infatti per interagire con noi in modi simili a quelli con cui noi ci relazioniamo con le altre persone. Scelta dettata anche da esigenze di marketing: venendo presentati al mercato come nostri aiutanti e assistenti, una presunta somiglianza li rende maggiormente comprensibili, accettabili e, soprattutto, appetibili.

Al di là dei disclaimer posizionati nelle homepage dei progetti, penso sia necessario qualche sforzo in più per contrastare questa equivocità. Una comunicazione meno portata ad esagerare le somiglianze tra esseri umani e macchine ma che ne enfatizza invece le differenze; iniziative di formazione su larga scala volte ad educare le persone circa i limiti delle IA e il loro ruolo funzionale; la promozione (e non il contrasto) di team di ricerca interdisciplinari che, abbracciando discipline come la filosofia, la linguistica, l'etica e la semantica, possano dare un contributo forte in questo senso.

L'accelerazione di queste tecnologie è sotto gli occhi di tutti: non attendiamo oltre.